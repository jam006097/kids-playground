# AI API 開発ガイド

このドキュメントは、Hugging Face SpacesとGradioを利用したAI APIの開発環境構築と、その後の開発プロセスに関する要点をまとめたものです。

## 1. 概要

### 1.1. 目的と機能概要

本プロジェクトの目的は、「親子で遊ぼうナビ」にAIを活用した**口コミの自動要約機能**を実装することです。

- **目的:** ユーザーが多数の口コミを全て読んでも、施設の全体的な評判を素早く、かつ客観的に把握できるようにする。
- **ユーザー体験:**
    1. ユーザーは施設の詳細ページで「口コミをAI要約」ボタンをクリックします。
    2. AIがその施設の全口コミを分析し、「ポジティブな点」と「注意が必要な点」などをまとめた中立的な要約文を生成します。
    3. 生成された要約がモーダルウィンドウ等で表示され、ユーザーは短時間で施設の長所と短所を理解できます。

### 1.2. アーキテクチャ

この機能は、Djangoアプリケーションと、Hugging Face Spaces上で動作するGradio APIとの連携によって実現します。

- **開発環境:** Dockerコンテナ内で開発・テストを行う。
- **バージョン管理:** Gitでコードを管理する。
- **CI/CD:** GitHub Actionsでテストとデプロイを自動化する。
- **本番環境:** Hugging Face Spacesにデプロイし、APIを公開する。

---

## 2. プロジェクト構造と開発環境

保守性・拡張性を高めるため、役割ごとにファイルを分割したディレクトリ構造を採用し、Dockerで開発環境を構築します。

### 2.1. 推奨ディレクトリ構造

```
kids-playground-ai-api/
│
├── .github/
│   └── workflows/
│       └── ci.yml
│
├── .gitignore
├── Dockerfile
├── pyproject.toml
├── requirements.txt
├── README.md
│
├── src/
│   └── ai_api/
│       ├── __init__.py
│       ├── main.py         # APIエントリーポイント (Gradio UI)
│       ├── core/
│       │   ├── __init__.py
│       │   └── inference.py  # AI推論ロジック
│       └── config.py       # 設定ファイル
│
└── tests/
    └── core/
        └── test_inference.py
```

### 2.2. 品質管理ツールの設定

- **`pyproject.toml`:** プロジェクトルートに作成し、Ruff (フォーマッター/リンター), Mypy (型チェッカー), Pytest (テストフレームワーク) の設定を記述します。
- **`.pre-commit-config.yaml`:** `pre-commit`を導入し、Gitコミット時に自動でコードチェックが走るように設定します。

### 2.3. 開発環境 (Docker)

- **`requirements.txt`:** 必要なライブラリを記述します。
- **`Dockerfile`:** ローカル開発環境の統一と効率化のために使用します。
    - **注記:** この`Dockerfile`は、あくまでローカル開発用です。デプロイ先のHugging Face Spacesでは、`Dockerfile`は直接使われず、`requirements.txt`に基づいて環境が自動構築されます。

---

## 3. モデル管理

- **モデル選定:** まずは速度とリソースのバランスが良い軽量なモデル（例: `llm-jp/t5-small-japanese-finetuned-sum`）で開発を開始し、必要に応じて、より高品質なモデル（例: `izumi-lab/t5-base-japanese-summary`）への差し替えを検討します。
- **情報記録:** `config.py`には、モデル名だけでなく、モデルサイズ、ライセンス、推論速度の目安などの情報もコメントとして記録し、管理します。

---

## 4. 実装の役割分担

- **`src/ai_api/config.py` (設定担当):** モデルやパラメータの情報を管理します。
- **`src/ai_api/core/inference.py` (AI推論担当):** AIモデルのロードと推論のコアロジックを実装します。
- **`src/ai_api/main.py` (API受付担当):** GradioのUIを定義し、サーバーを起動します。Dockerコンテナ内で外部にAPIを公開するため、`iface.launch(server_name="0.0.0.0")`のように起動オプションを指定します。

---

## 5. テスト戦略

- **ユニットテスト:** `pytest`を使い、`inference.py`内の純粋な関数（AIのコアロジック）をテストします。
- **インテグレーションテスト:** ローカルで起動したGradioサーバーに対し、`requests`ライブラリで実際にAPIリクエストを送り、HTTPステータスコードやレスポンスの形式が期待通りであることを確認するテストも追加します。これにより、APIとしての正常性を保証します。

---

## 6. CI/CDとデプロイ戦略

### 6.1. 推奨ワークフロー
1.  **CI (GitHub Actions):** プルリクエスト作成時やmainブランチへのプッシュ時に、GitHub Actionsを起動し、`pytest`による自動テスト（ユニットテストとインテグレーションテスト）を実行します。
2.  **CD (Hugging Face Hub連携):** テストが成功したコードがmainブランチにマージされたら、Hugging Face Hubの**GitHub連携機能**がそれを検知し、自動的にSpacesにデプロイします。この方法が、Actionsから手動で`git push`するよりシンプルで確実なため推奨されます。

### 6.2. 設定
- **GitHub Actions:** `.github/workflows/ci.yml`にテストのワークフローを定義します。
- **Hugging Face Hub:** Spacesの設定ページで、対象のGitHubリポジトリとブランチを指定して連携を有効化します。

---

## 7. セキュリティと利用制限

- **Abuse対策:** 公開APIが悪用されるのを防ぐため、Gradioの`queue()`メソッドを利用してリクエストを待ち行列に入れ、同時アクセス数を制限することを検討します。
- **免責事項:** `README.md`に、APIの利用は自己責任であること、生成される内容の正確性を保証しないこと、商用利用に関する制限などを明記しておきます。

---

## 8. 今後の開発プロセス

このドキュメントは、今後の調査や開発の進捗に応じて、継続的に更新・メンテナンスされます。

---

## 9. 設計

このセクションでは、機能実装の前に定義するべき、より詳細な設計について記録します。

### 9.1. APIインターフェース設計 (口コミ要約機能 v1)

DjangoとGradio APIがやり取りするデータ形式とルールを以下のように定めます。

#### 9.1.1. 基本方針
- **通信プロトコル:** HTTP/HTTPS
- **データ形式:** JSON
- **基本構造:** Gradioの標準API形式に準拠します。

#### 9.1.2. リクエスト仕様 (Django → Gradio API)
- **エンドポイント:** `(SpaceのURL)/api/predict/`
- **HTTPメソッド:** `POST`
- **ボディ (JSON):**
  ```json
  {
    "data": [
      "口コミ全文を結合した文字列..."
    ]
  }
  ```

#### 9.1.3. レスポンス仕様 (Gradio API → Django)
**成功時 (HTTP 200 OK):**
- **ボディ (JSON):**
  ```json
  {
    "data": [
      "AIによって生成された要約文..."
    ],
    "duration": 3.5
  }
  ```

**失敗時 (HTTP 500 Internal Server Error):**
- **ボディ (JSON):**
  ```json
  {
    "error": "Gradio側で設定したエラーメッセージ"
  }
  ```

### 9.2. UI/UX設計 (口コミ要約機能 v1)

ユーザーが機能を直感的に利用でき、システムの応答を快適に待てるように、以下の通りUI/UXを設計します。

#### 9.2.1. 操作フロー
1.  **トリガー:** ユーザーが施設詳細ページの「口コミをAI要約」ボタンをクリックします。
2.  **ローディング:** ボタンが無効化され、「生成中です...」というテキストとスピナー（回転するアイコン）が表示されます。これにより、処理中であることがユーザーに明確に伝わります。
3.  **結果表示:** 要約が完了すると、**Bootstrapのモーダルウィンドウ**が画面中央に表示され、その中に生成された要約文が提示されます。
4.  **完了:** ユーザーはモーダルを閉じて、元のページ閲覧を続けます。ローディング表示は元のボタン表示に戻ります。

#### 9.2.2. エッジケースの対応
- **口コミが少ない場合:**
    - **条件:** Django側で、対象施設の口コミが3件未満の場合。
    - **処理:** AIのAPIは呼び出さず、即座に「口コミが3件未満のため、要約できません。」というアラートメッセージを表示します。これにより、不要なAPIコールを防ぎ、ユーザーに状況を的確に伝えます。
- **APIエラー発生時:**
    - **条件:** APIのタイムアウトやサーバーエラーが発生した場合。
    - **処理:** 「AIサーバーで問題が発生しました。時間をおいて再度お試しください。」といった内容をアラートまたはモーダルで表示します。

### 9.3. データ処理・ビジネスロジック設計 (v1)

AIの性能を最大限に引き出し、安定した運用を行うための内部ルールを以下のように設計します。

#### 9.3.1. 入力データの前処理 (Django側)
- **口コミの結合:** 複数の口コミは、それぞれを独立した段落としてAIに認識させるため、2つの改行文字 (`\n\n`) で区切って1つのテキストに結合します。
- **ノイズ除去:** 絵文字やURLなど、要約のノイズとなりうる不要な文字列は、正規表現を用いて事前に除去します。

#### 9.3.2. 要約実行の判断ロジック (Django側)
以下の条件を満たさない場合は、APIを呼び出さずにエラーとして処理します。
- **最小口コミ件数:** 3件以上
- **最小総文字数:** 全体の文字数が300文字以上

#### 9.3.3. AIモデルの推論パラメータ (Gradio API側)
生成される要約文の品質を制御するため、以下の初期パラメータを設定します。これらの値は `config.py` で管理し、調整可能にします。
- **要約文の最小長 (`min_length`):** 50
- **要約文の最大長 (`max_length`):** 250
- **長さペナルティ (`length_penalty`):** 2.0 (冗長な表現を抑制)

#### 9.3.4. 大量データへの対応方針
- **初期実装:** まずは全ての口コミを結合してAPIに送信します。モデルの最大入力長を超える場合は、`truncation=True` オプションにより自動的に末尾が切り捨てられます。
- **将来的な改善:** 性能やコストに問題が見られた場合、「直近1年間の口コミのみを対象とする」などの制限を後から追加することを検討します。

### 9.4. エラーハンドリング設計 (v1)

予期せぬ事態が発生した場合でもシステムが安定して動作し、ユーザーに適切なフィードバックを返せるよう、以下の通りエラーハンドリングを設計します。

#### 9.4.1. エラー発生源と対応方針

| 発生場所 | エラー例 | 対応方針 | ユーザーへの通知例 |
| :--- | :--- | :--- | :--- |
| **Gradio API** | モデルのロード失敗、推論中のエラー | `try...except`で捕捉し、HTTP 500とエラー内容をJSONで返す。 | (Django経由で)「AIサーバーで問題が発生」 |
| **Django ⇔ Gradio API間** | ネットワーク障害、タイムアウト | Djangoの`requests`部分で`try...except`で捕捉し、エラーをログ記録。 | 「AIサーバーに応答がありません」 |
| **Django** | DB接続エラー、口コミ件数不足 | `try...except`や条件分岐で対応。口コミ不足はHTTP 400を返す。 | 「サーバーでエラーが発生」、または「口コミが不足」 |
| **ブラウザ ⇔ Django間** | ユーザーのオフライン | jQuery Ajaxの`.fail()`コールバックで捕捉。 | 「通信に失敗しました」 |

#### 9.4.2. 実装のポイント
- **Django (司令塔) の役割:**
    - Djangoのビューは、Gradio APIとの通信部分を必ず`try...except`ブロックで囲み、タイムアウト（例: 30秒）を設定します。
    - APIから返されたHTTPステータスコードを常にチェックし、200番台以外はエラーとして処理します。
    - 発生したエラーは、**必ずサーバーログに記録**し、原因調査に役立てます。
    - ユーザーには、技術的なエラー詳細（スタックトレース等）を直接見せず、「AIサーバーで問題が発生しました」のような抽象的で分かりやすいメッセージを返します。

- **Gradio API (専門家) の役割:**
    - AIの推論処理など、失敗する可能性のあるコードは`try...except`ブロックで囲みます。
    - エラー発生時は、`raise gr.Error("具体的なエラー原因")`を呼び出し、APIの契約通りにエラー情報を返却します。

### 9.5. 詳細設計: AI推論コア (`core/inference.py`) (v1)

AI推論のコアロジックは、保守性とテスト容易性を高めるために、いくつかの設計原則とデザインパターンを適用して構造化します。

#### 9.5.1. クラス設計と責務
- **`Summarizer` クラスの導入:** AIの推論に関連する全てのロジックを、単一の`Summarizer`クラスに集約します。このクラスは**「AIモデルを管理し、テキスト要約を実行する」**という明確な責務を持ちます。

#### 9.5.2. 適用するデザインパターン
- **ファサード (Facade) パターン:** `Summarizer`クラスは、`transformers`ライブラリの複雑な内部処理（モデルのロード、トークナイズ、推論、デコード等）をカプセル化（隠蔽）します。そして、`summarize(text)`という非常にシンプルなメソッドのみを外部に公開します。これにより、利用側（`main.py`）はAIの複雑な詳細を意識することなく、簡単かつ安全に要約機能を利用できます。

- **シングルトン (Singleton) パターン:** AIモデルのロードはリソースを大量に消費する重い処理です。そのため、`Summarizer`クラスのインスタンスは、アプリケーションの起動時に一度だけ生成し、以降はアプリケーション全体でその単一のインスタンスを共有します。これにより、リクエストごとにモデルをロードする無駄をなくし、効率的なリソース利用を実現します。これはモジュールレベルでインスタンスを生成することで、シンプルに実現します。

- **依存性の注入 (Dependency Injection):** `Summarizer`クラスは、使用するモデル名や要約の長さといった設定値を、コンストラクタを通じて外部の`config`モジュールから受け取ります。このように、コンポーネントが必要とする依存関係（この場合は設定値）を外部から与える設計により、`Summarizer`クラスと特定の設定値との結合を弱め（疎結合）、テストや設定の変更が容易になります。

#### 9.5.3. エラーハンドリング方針
- `Summarizer`クラス内で発生したエラー（モデルのロード失敗、推論失敗など）は、クラス内部で適切に捕捉され、呼び出し元がハンドリングしやすいように、専用の例外（例: `InferenceError`）として再送出する設計とします。

### 9.6. 詳細設計: 設定管理 (`config.py`) (v1)

設定値をコードから分離し、安全かつ構造的に管理するため、以下の通り設計します。

#### 9.6.1. 設計方針
- **データクラスの活用:** Python標準の`dataclasses`を用い、関連する設定項目をグループ化した設定クラス（例: `ModelConfig`）を定義します。これにより、型安全性が保証され、コード補完も効くため開発効率が向上します。
- **不変性の確保:** 作成したデータクラスは `@dataclass(frozen=True)` を指定し、イミュータブル（変更不可能）にします。これにより、アプリケーション実行中に意図せず設定が変更されてしまう危険な状態を防ぎます。
- **環境変数による設定の上書き:** 将来的な拡張性（例: APIキーの管理）を見据え、設定値は環境変数から取得することを基本とします。開発環境では`.env`ファイルを利用し、本番環境では実行環境（Hugging Face Spacesなど）のSecrets機能で設定を注入する運用を想定します。

#### 9.6.2. 構造案
- **`ModelConfig` クラス:**
    - **責務:** 使用するAIモデルに関する情報を一元管理します。
    - **属性案:** `NAME` (モデル名), `REVISION` (バージョン)
- **`InferenceConfig` クラス:**
    - **責務:** AIの推論（要約生成）時のパラメータを一元管理します。
    - **属性案:** `MIN_LENGTH`, `MAX_LENGTH`, `LENGTH_PENALTY`, `NUM_BEAMS`

### 9.7. 詳細設計: Django側ビュー (`summary_views.py`) (v1)

Django側でAI APIを呼び出すビューは、責務を明確に分離し、堅牢なエラーハンドリングとロギングを組み込んだクラスとして設計します。

#### 9.7.1. 設計方針
- **クラスベースビュー (CBV) の採用:** Django標準の`django.views.View`を継承したクラスとして実装します。これにより、将来的な機能拡張（例: POSTメソッドの追加）にも柔軟に対応できます。
- **責務の分離:** 1つのメソッドに全てのロジックを記述するのではなく、「口コミの取得」「バリデーション」「API呼び出し」といった関心事ごとにプライベートメソッド（例: `_call_api`）へ処理を分割し、メインの`get`メソッドの見通しを良くします。
- **集中的なエラーハンドリング:** メインの`get`メソッドに`try...except`ブロックを設け、各処理で発生しうる例外（DB関連、通信関連など）を集中的に捕捉し、適切な`JsonResponse`を返すようにします。
- **詳細なロギング:** Pythonの`logging`モジュールを活用し、API呼び出しの成否、発生したエラー、ビジネスロジックの判断などをログに出力します。特にエラー発生時には、スタックトレースを含めて記録することで、迅速な原因究明を可能にします。

#### 9.7.2. クラス・メソッド構成案
- **`SummarizeReviewsView(View)`**
    - **`get(self, request, playground_id)`:**
        - HTTP GETリクエストを処理するメインメソッド。
        - 以下の処理フローを制御する。
            1. `_get_reviews`を呼び出し、口コミデータを取得。
            2. `_validate_reviews`を呼び出し、ビジネスルール（件数、文字数）を検証。
            3. 口コミテキストを前処理（結合、ノイズ除去）。
            4. `_call_summary_api`を呼び出し、外部APIと通信。
            5. 成功レスポンスまたはエラーレスポンスを`JsonResponse`として返す。
    - **`_get_reviews(self, playground_id)`:**
        - `playground_id`に対応する口コミをデータベースから取得する責務を持つ。
    - **`_validate_reviews(self, reviews)`:**
        - 取得した口コミが要約実行の条件を満たすか検証する責務を持つ。
    - **`_call_summary_api(self, text)`:**
        - `requests`ライブラリを使い、Gradio APIとの通信を行う責務を持つ。タイムアウト設定もここで行う。

#### 9.7.3. 設定値の管理
- Gradio APIのエンドポイントURLやタイムアウト秒数といった設定値は、`settings.py`に記述し、ビューからは`django.conf.settings`を通じて参照します。これにより、設定の一元管理を実現します。

### 9.8. 詳細設計: テスト戦略の具体化 (v1)

アプリケーションの品質と信頼性を保証するため、以下の通り多層的なテスト戦略を設計します。

#### 9.8.1. テストの種類と目的
- **ユニットテスト (Unit Tests):**
    - **目的:** 個々の部品（クラス、メソッド）が単体で正しく動作することを検証します。高速に実行できるため、開発中の頻繁な確認に適しています。
    - **対象:** `core/inference.py` の `Summarizer` クラスなど、ビジネスロジックの中核を担う部分。
- **インテグレーションテスト (Integration Tests):**
    - **目的:** Gradio APIのエンドポイントが、APIの契約通りに正しくリクエストを処理し、レスポンスを返すことを検証します。コンポーネント間の連携を確認します。
    - **対象:** ローカルで起動したGradioアプリケーションの `/api/predict/` エンドポイント。

#### 9.8.2. テストケースの計画
- **ユニットテスト (`tests/core/test_inference.py`):**
    - **正常系:** 通常のテキストが入力された場合に、期待される形式（文字列）の要約が返ることを確認する。
    - **異常系:** 空文字列や不正なデータ型が入力された場合に、設計通り`ValueError`等の例外が発生することを確認する。
- **インテグレーションテスト (`tests/test_api.py`):**
    - **正常系:** APIに有効なリクエストを送信し、HTTPステータスコード`200`と、設計通りのJSONレスポンスが返ることを確認する。
    - **異常系:** 不正なリクエストを送信した場合に、適切なHTTPエラーステータスコード（例: `4xx`）が返ることを確認する。

#### 9.8.3. テストの効率化
- **フィクスチャの活用 (`@pytest.fixture`):** AIモデルのロードは時間がかかるため、`Summarizer`クラスのインスタンス生成をフィクスチャとして定義します。`scope="session"`を指定することで、全テスト実行中にモデルのロードが一度だけで済み、テスト時間を大幅に短縮します。
- **パラメータ化の活用 (`@pytest.mark.parametrize`):** 複数の異なる入力値と期待される結果の組み合わせを、一つのテスト関数で効率的に検証するために使用します。
